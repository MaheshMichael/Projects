{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbYOAxVclp6O"
      },
      "source": [
        "# 01. Learning LangGraph - Agent Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoQEqlXGrWi",
        "outputId": "f0cffff7-c310-48a7-a50a-4f27cdb61d55"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet -U langchain langchain_openai langgraph langchainhub langchain_experimental\n",
        "# !pip install PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yS-Jzh_a_eI"
      },
      "source": [
        "modified from https://github.com/langchain-ai/langgraph/blob/main/examples/agent_executor/base.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "guac0Zh7Gz4Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv  # Importing dotenv to load environment variables from a .env file\n",
        "import openai\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"ENDPOINT\"] = os.getenv('ENDPOINT')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zHfhDLnHUhU"
      },
      "source": [
        "## Making the GraphState"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Bz48n-NHOXa"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "   # The input string\n",
        "   input: str\n",
        "   # The list of previous messages in the conversation\n",
        "   chat_history: list[BaseMessage]\n",
        "   # The outcome of a given call to the agent\n",
        "   # Needs `None` as a valid type, since this is what this will start as\n",
        "   agent_outcome: Union[AgentAction, AgentFinish, None]\n",
        "   # List of actions and corresponding observations\n",
        "   # Here we annotate this with `operator.add` to indicate that operations to\n",
        "   # this state should be ADDED to the existing values (not overwrite it)\n",
        "   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjkCAE7ZJjdc"
      },
      "source": [
        "## Custom Tools\n",
        "\n",
        "**Tools**  \n",
        "\n",
        "Tools are interfaces that an agent can use to interact with the world. They combine a few things:\n",
        "\n",
        "\n",
        "\n",
        "1.   The name of the tool\n",
        "2.   A description of what the tool is\n",
        "3.   JSON schema of what the inputs to the tool are\n",
        "4.   The function to call\n",
        "\n",
        "\n",
        "Whether the result of a tool should be returned directly to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'AssistantAgent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m assistant \u001b[38;5;241m=\u001b[39m \u001b[43mAssistantAgent\u001b[49m(\n\u001b[0;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m600\u001b[39m,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: config_list,\n\u001b[0;32m      8\u001b[0m     },\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m ragproxyagent \u001b[38;5;241m=\u001b[39m RetrieveUserProxyAgent(\n\u001b[0;32m     11\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mragproxyagent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEVER\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     code_execution_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# set to False if you don't want to execute the code\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'AssistantAgent' is not defined"
          ]
        }
      ],
      "source": [
        "assistant = AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    system_message=\"You are a helpful assistant.\",\n",
        "    llm_config={\n",
        "        \"timeout\": 600,\n",
        "        \"cache_seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    },\n",
        ")\n",
        "ragproxyagent = RetrieveUserProxyAgent(\n",
        "    name=\"ragproxyagent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=3,\n",
        "    retrieve_config={\n",
        "        \"task\": \"code\",\n",
        "        \"docs_path\": [\n",
        "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n",
        "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n",
        "            os.path.join(os.path.abspath(\"\"), \"..\", \"website\", \"docs\"),\n",
        "        ],\n",
        "        \"custom_text_types\": [\"mdx\"],\n",
        "        \"chunk_token_size\": 2000,\n",
        "        \"model\": config_list[0][\"model\"],\n",
        "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
        "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
        "        \"get_or_create\": True,  # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually\n",
        "    },\n",
        "    code_execution_config=False,  # set to False if you don't want to execute the code\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OLeIVeaEJltj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizedQuery\n",
        "import openai\n",
        "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
        "import logging\n",
        "\n",
        "@tool(\"lower_case\", return_direct=True)\n",
        "def to_lower_case(input:str) -> str:\n",
        "  \"\"\"Returns the input as all lower case.\"\"\"\n",
        "  return input.lower()\n",
        "\n",
        "@tool(\"random_number\", return_direct=True)\n",
        "def random_number_maker(input:str) -> str:\n",
        "    \"\"\"Returns a random number between 0-100.\"\"\"\n",
        "    return random.randint(0, 100)\n",
        "\n",
        "@tool(\"search_similar_documents\", return_direct=True)\n",
        "def search_similar_documents(user_query: str):\n",
        "    \"\"\"\n",
        "    Get embeddings for the user query and search for similar documents in Azure Search.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The input query to search for similar documents.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints the search results directly.\n",
        "    \"\"\"\n",
        "    # Load Azure Search service configuration from environment variables\n",
        "    service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
        "    index_name = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "    key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "    k_nearest_neighbors = 3  # Number of nearest neighbors to retrieve\n",
        "\n",
        "    # Load OpenAI configuration from environment variables\n",
        "    open_ai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    open_ai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "\n",
        "    # Initialize OpenAI client\n",
        "    openai_client = openai.AzureOpenAI(\n",
        "        azure_endpoint=open_ai_endpoint,\n",
        "        api_key=open_ai_key,\n",
        "        api_version=\"2023-03-15-preview\",\n",
        "    )\n",
        "\n",
        "    # Get embeddings for the user query\n",
        "    embedding = openai_client.embeddings.create(input=[user_query], model=\"text-embedding-ada-002\")\n",
        "    query_vector = embedding.data[0].embedding\n",
        "\n",
        "    # Initialize the Azure Search client\n",
        "    search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
        "\n",
        "    # Create a vectorized query\n",
        "    vector_query = VectorizedQuery(\n",
        "        vector=query_vector,\n",
        "        k_nearest_neighbors=k_nearest_neighbors,\n",
        "        fields=\"chunkVector\",\n",
        "    )\n",
        "\n",
        "    # Execute the hybrid search\n",
        "    results = search_client.search(\n",
        "        search_text= \"Payroll Summary\",\n",
        "        vector_queries=[vector_query],\n",
        "        select=[\"chunkId\", \"parentDoc\", \"chunk\"],\n",
        "    )\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Search Results:\")\n",
        "    for result in results:\n",
        "        print(f\"Chunk ID: {result['chunkId']}, Parent Document: {result['parentDoc']}, Chunk: {result['chunk']}\")\n",
        "\n",
        "tools = [to_lower_case,random_number_maker,search_similar_documents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnqHbU-3LSe_",
        "outputId": "ea9f2a6f-6ee0-4dcd-d033-1bb1048f0634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_number_maker.run('random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search Results:\n"
          ]
        },
        {
          "ename": "ResourceNotFoundError",
          "evalue": "() The index 'socr-test-idx' for service 'uscdadvecnazs01' was not found.\nCode: \nMessage: The index 'socr-test-idx' for service 'uscdadvecnazs01' was not found.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msearch_similar_documents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\langchain_core\\tools\\base.py:722\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    721\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    723\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    724\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\langchain_core\\tools\\base.py:690\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    689\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 690\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\langchain_core\\tools\\structured.py:80\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m     79\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructuredTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
            "Cell \u001b[1;32mIn[9], line 71\u001b[0m, in \u001b[0;36msearch_similar_documents\u001b[1;34m(user_query)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChunk ID: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunkId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Parent Document: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparentDoc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Chunk: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\search\\documents\\_paging.py:54\u001b[0m, in \u001b[0;36mSearchItemPaged.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m     first_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_iterator_instance()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(first_iterator)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_page_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\core\\paging.py:75\u001b[0m, in \u001b[0;36mPageIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of paging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\search\\documents\\_paging.py:125\u001b[0m, in \u001b[0;36mSearchPageIterator._get_next_cb\u001b[1;34m(self, continuation_token)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_next_cb\u001b[39m(\u001b[38;5;28mself\u001b[39m, continuation_token):\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continuation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     _next_link, next_page_request \u001b[38;5;241m=\u001b[39m unpack_continuation_token(continuation_token)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39mnext_page_request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\search\\documents\\_generated\\operations\\_documents_operations.py:752\u001b[0m, in \u001b[0;36mDocumentsOperations.search_post\u001b[1;34m(self, search_request, request_options, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[1;32m--> 752\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n",
            "File \u001b[1;32mc:\\Users\\TH967NM\\AppData\\Local\\anaconda3\\envs\\Langgraph\\Lib\\site-packages\\azure\\core\\exceptions.py:163\u001b[0m, in \u001b[0;36mmap_error\u001b[1;34m(status_code, response, error_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    162\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "\u001b[1;31mResourceNotFoundError\u001b[0m: () The index 'socr-test-idx' for service 'uscdadvecnazs01' was not found.\nCode: \nMessage: The index 'socr-test-idx' for service 'uscdadvecnazs01' was not found."
          ]
        }
      ],
      "source": [
        "search_similar_documents.run(\"chunk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8X4Es0EJaYb7",
        "outputId": "f954ca4a-e43b-4609-c158-22d47f9ed159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sam'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_lower_case.run('SAM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSl1IkYEqTKx"
      },
      "source": [
        "## Agent - with new create_open_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZRfmuHYoqR-H"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_openai import AzureChatOpenAI \n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Choose the LLM that will drive the agent\n",
        "llm = AzureChatOpenAI(model=\"gpt-4o\",azure_endpoint = os.getenv('ENDPOINT') , streaming=True)\n",
        "\n",
        "# Construct the OpenAI Functions agent\n",
        "agent_runnable = create_openai_functions_agent(llm,\n",
        "                                               tools,\n",
        "                                               prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YitzfHjZq4bv",
        "outputId": "83df8a9d-ffdd-4dea-fb9c-1defc36ca76d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000277404A2E80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000277404A2E80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enowMbGUwEXb",
        "outputId": "d71298f0-6249-43d5-d765-a983f55c83c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001F14218B420>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001F14218B420>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.get_prompts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GJ7_ezEUvpjv"
      },
      "outputs": [],
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\",\n",
        "          \"chat_history\": [],\n",
        "          \"intermediate_steps\":[]}\n",
        "\n",
        "agent_outcome = agent_runnable.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVco6-WmB1ll",
        "outputId": "dfdef23b-69c7-4b66-ce26-7bab916e2970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='random_number', tool_input={'input': 'give random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'give random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"give random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-00668c33-05ca-4ebd-866d-137d3087fa87-0')])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux7k8XD0B90p",
        "outputId": "081af95c-70de-48d6-f7be-4ea4481d00c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.runnables.base.RunnableSequence"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(agent_runnable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEgS5eK_HdvK"
      },
      "source": [
        "## Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9gmzMROGHqeN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TH967NM\\AppData\\Local\\Temp\\ipykernel_13292\\2882498864.py:4: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
            "  tool_executor = ToolExecutor(tools)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JyRrGocuHZ2b"
      },
      "outputs": [],
      "source": [
        "# Define the agent/graph\n",
        "def run_agent(data):\n",
        "    agent_outcome = agent_runnable.invoke(data)\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "# Define the function to execute tools\n",
        "def execute_tools(data):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_action = data['agent_outcome']\n",
        "    # Execute the tool\n",
        "    output = tool_executor.invoke(agent_action)\n",
        "    print(f\"The agent action is {agent_action}\")\n",
        "    print(f\"The tool result is: {output}\")\n",
        "    # Return the output\n",
        "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
        "\n",
        "# Define logic that will be used to determine which conditional edge to go down\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if isinstance(data['agent_outcome'], AgentFinish):\n",
        "        return \"end\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SatNeMOsIWLx"
      },
      "source": [
        "## Define the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tAG5MVUxIXr_"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge('action', 'agent')\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000001F154BFC500>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP7CPbYyDS_q",
        "outputId": "a87ebdd5-f252-4440-8990-8e7b63164d0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {'agent': {'should_continue': Branch(path=should_continue(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), ends={'continue': 'action', 'end': '__end__'}, then=None)}})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.branches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmdeWSiVDcLC",
        "outputId": "f197500a-9687-4d76-a306-c40a1f5bea73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'agent': StateNodeSpec(runnable=agent(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.AgentState'>, retry_policy=None, ends=()),\n",
              "  'action': StateNodeSpec(runnable=action(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.AgentState'>, retry_policy=None, ends=())},\n",
              " {('__start__', 'agent'), ('action', 'agent')})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.nodes , workflow.edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVfXfUtID0r7",
        "outputId": "634c8e3e-8975-4478-ebf7-8957524eb6cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': <langgraph.channels.last_value.LastValue at 0x1f154ccd4c0>,\n",
              " 'chat_history': <langgraph.channels.last_value.LastValue at 0x1f15491db40>,\n",
              " 'agent_outcome': <langgraph.channels.last_value.LastValue at 0x1f154ccde80>,\n",
              " 'intermediate_steps': <langgraph.channels.binop.BinaryOperatorAggregate at 0x1f154ccd780>}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.channels #['intermediate_steps']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr_c40yBpr4f",
        "outputId": "c5838f2a-5381-4444-fe70-11aa06edfbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_values([{'agent_outcome': AgentActionMessageLog(tool='random_number', tool_input={'input': 'give me a random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'give me a random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"give me a random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-bfc6c5dc-9c00-47a7-8665-8fb1cae77f2d-0')])}])\n",
            "----\n",
            "The agent action is tool='random_number' tool_input={'input': 'give me a random number'} log=\"\\nInvoking: `random_number` with `{'input': 'give me a random number'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"give me a random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-bfc6c5dc-9c00-47a7-8665-8fb1cae77f2d-0')]\n",
            "The tool result is: 76\n",
            "dict_values([{'intermediate_steps': [(AgentActionMessageLog(tool='random_number', tool_input={'input': 'give me a random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'give me a random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"give me a random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-bfc6c5dc-9c00-47a7-8665-8fb1cae77f2d-0')]), '76')]}])\n",
            "----\n",
            "dict_values([{'agent_outcome': AgentFinish(return_values={'output': 'The random number is 76. In words, it is \"seventy-six.\" In lower case, it is \"seventy-six.\"'}, log='The random number is 76. In words, it is \"seventy-six.\" In lower case, it is \"seventy-six.\"')}])\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\", \"chat_history\": []}\n",
        "for s in app.stream(inputs): \n",
        "    print(list(s.values())[0])\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGT9kXywqJGM",
        "outputId": "c6cd9ead-3a96-401e-e1b2-8c88008b218a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The agent action is tool='random_number' tool_input={'input': 'random'} log=\"\\nInvoking: `random_number` with `{'input': 'random'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-9dcafe09-7715-4324-a042-fbeed792a86f-0')]\n",
            "The tool result is: 60\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
        "\n",
        "output = app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-YfntCeAuOPG",
        "outputId": "e9982d57-3036-4d0d-baf4-f4718d59a677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The random number is sixty.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.get(\"agent_outcome\").return_values['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErubbyceuOPH",
        "outputId": "d3bb7472-efed-4092-8daa-473c5fceaaf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(AgentActionMessageLog(tool='random_number', tool_input={'input': 'random'}, log=\"\\nInvoking: `random_number` with `{'input': 'random'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65'}, id='run-9dcafe09-7715-4324-a042-fbeed792a86f-0')]),\n",
              "  '60')]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.get(\"intermediate_steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_mSFW-4Crpyd"
      },
      "outputs": [],
      "source": [
        "inputs = {\"input\": \"does it get cold in SF in Jan?\", \"chat_history\": []}\n",
        "output = app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yd88Rrmftqa3",
        "outputId": "c5b4725f-dab4-4399-9100-07fd51084ceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, it can get cold in San Francisco in January. While San Francisco generally has a mild climate, January is one of the colder months. Average temperatures typically range from the mid-40s to the mid-50s Fahrenheit (around 7-13 degrees Celsius). It can be quite chilly, especially with the wind and dampness, so it's a good idea to dress warmly if you're visiting during this time.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.get(\"agent_outcome\").return_values['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4HwY9Ept0c2",
        "outputId": "d9c4db24-5dd1-4451-e08d-f68660293da9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.get(\"intermediate_steps\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Langgraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
